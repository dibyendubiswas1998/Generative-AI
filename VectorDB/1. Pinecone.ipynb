{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGUKFc8CYlKuiMt3XKYFhE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Vector Database Pinecone:**"],"metadata":{"id":"Ld7l_GnD9ao5"}},{"cell_type":"markdown","source":["## **Install Pinecone:**"],"metadata":{"id":"yBIJVFDsx4pi"}},{"cell_type":"code","source":["!pip install \"pinecone[grpc]\" -qU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tn40vj2C9ZY_","executionInfo":{"status":"ok","timestamp":1728905300553,"user_tz":-330,"elapsed":16292,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"5d859796-6b16-473d-a733-bba1983a50b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.16.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["## **Create Index (Serverless):**"],"metadata":{"id":"2R_xsjXIyjHR"}},{"cell_type":"code","source":["from pinecone.grpc import PineconeGRPC as Pinecone\n","from pinecone import ServerlessSpec\n","\n","pc = Pinecone(api_key=\"pinecone-api-key\")\n","\n","pc.create_index(\n","  name=\"test\",\n","  dimension=1536,\n","  metric=\"cosine\",\n","  spec=ServerlessSpec(\n","    cloud=\"aws\",\n","    region=\"us-east-1\"\n","  ),\n","  deletion_protection=\"disabled\" # enabled means index never deleted, disabled means index can be deleted.\n",")"],"metadata":{"id":"_Cnaqzpt9Zb7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load the Documents:**"],"metadata":{"id":"QVjQBT-V0cHc"}},{"cell_type":"code","source":["!pip install langchain -qU\n","!pip install langchain_community -qU\n","!pip install unstructured[pdf] -qU\n","!pip install pypdfium2 -qU"],"metadata":{"id":"htaF-srS9Zet","executionInfo":{"status":"ok","timestamp":1728999022519,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### **Load 2 Pdfs:**"],"metadata":{"id":"qDkvPDBa3cz_"}},{"cell_type":"code","source":["from langchain_community.document_loaders import PDFPlumberLoader, PyPDFium2Loader\n","from pathlib import Path\n","from IPython.display import display, Markdown\n","\n","# load the pdf documents:\n","\n","def load_pdf(file_path:Path):\n","  try:\n","    loader = PDFPlumberLoader(file_path)\n","    documents = loader.load()\n","    return documents, len(documents)\n","\n","  except Exception as ex:\n","    return ex"],"metadata":{"id":"-fmgRbOc9ZhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer_docs = load_pdf(Path(\"Research Paper Transformer.pdf\"))\n","transformer_docs = transformer_docs[0]"],"metadata":{"id":"-Krririu1mwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq2seq_docs = load_pdf(Path(\"Research Paper Sequence to Sequence Learning.pdf\"))\n","seq2seq_docs = seq2seq_docs[0]"],"metadata":{"id":"W2BEY8Aj3EFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"irNL9njv3uI-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Pre-processed the Docs:**"],"metadata":{"id":"rW1kDSii3gBP"}},{"cell_type":"code","source":["import re\n","\n","def clean_text(text):\n","    # Remove newlines, tabs, and extra spaces\n","    text = re.sub(r'[\\n\\t\\r]+', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text.strip()\n","\n","\n","def preprocess_documents(documents, subject):\n","    processed_docs = []\n","    for doc in documents:\n","        # Clean the page content\n","        cleaned_content = clean_text(doc.page_content)\n","\n","        # Create Structured Documents:\n","        processed_doc = {\n","            \"subject\": subject,\n","            \"source\": doc.metadata.get('source', ''),\n","            # \"file_path\": doc.metadata.get('file_path', ''),\n","            \"page\": doc.metadata.get('page', 0),\n","            \"total_pages\": doc.metadata.get('total_pages', 0),\n","            \"content\": cleaned_content\n","         }\n","\n","        processed_docs.append(processed_doc)\n","\n","    return processed_docs"],"metadata":{"id":"i3KwLQjI9ZjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer_pre_processed_docs = preprocess_documents(transformer_docs, \"Transformer\")\n","seq2seq_pre_processed_docs = preprocess_documents(seq2seq_docs, \"Sequence to Sequence Learning\")"],"metadata":{"id":"dXMzQ7YE9ZmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq2seq_pre_processed_docs"],"metadata":{"id":"7jk4TLI69ZpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uO5t4sR69Zuz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load Embedding Model:**"],"metadata":{"id":"VyP6oCMs6TBM"}},{"cell_type":"code","source":["!pip install boto3 -qU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Poj6lleN9Zxf","executionInfo":{"status":"ok","timestamp":1728998931069,"user_tz":-330,"elapsed":11434,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"0d6072df-817b-4920-e3fb-3cfe433c623f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/12.6 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m10.1/12.6 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m155.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/82.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import boto3\n","from langchain.llms.bedrock import Bedrock\n","from langchain.embeddings import BedrockEmbeddings\n","\n","AWS_REGION = ''\n","AWS_ACCESS_KEY = ''\n","AWS_SECRET_KEY = ''\n","\n","def get_embeddings():\n","  try:\n","    bedrock_client = boto3.client(\n","          service_name = \"bedrock-runtime\",\n","          region_name = AWS_REGION,\n","          aws_access_key_id = AWS_ACCESS_KEY,\n","          aws_secret_access_key = AWS_SECRET_KEY,\n","      )\n","    # The model_id was incorrect. Changing it to amazon.titan-text-embed-v1\n","    bedrock_embedding = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)\n","    return bedrock_embedding\n","\n","  except Exception as ex:\n","    return ex\n","\n","embedding_model = get_embeddings()"],"metadata":{"id":"eCw2yF0u6WWa","executionInfo":{"status":"ok","timestamp":1728999033224,"user_tz":-330,"elapsed":4366,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"168e75c8-8778-41e9-d007-c7e3b5a41081"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-f3a35d5e9a3c>:18: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockEmbeddings``.\n","  bedrock_embedding = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)\n"]}]},{"cell_type":"code","source":["hh = embedding_model.embed_query(\"Hello Wrold\")\n","len(hh)"],"metadata":{"id":"I0-_DErK6WY8","executionInfo":{"status":"aborted","timestamp":1728998931071,"user_tz":-330,"elapsed":12,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Store Embedding & Metadata into Pinecone:**"],"metadata":{"id":"-CXply8C_cLe"}},{"cell_type":"code","source":["from pinecone.grpc import PineconeGRPC as Pinecone\n","pc = Pinecone(api_key=\"\")\n","index = pc.Index(\"test\")"],"metadata":{"id":"PArI1M_p6WbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Store embeddings;\n","\n","def store_embeddings(docs, namespace, embeddings=embedding_model):\n","  vector_list = []\n","  for i, doc in enumerate(docs):\n","    metadata = {\n","        \"subject\": doc[\"subject\"],\n","        \"source\": doc[\"source\"],\n","        \"page\": doc[\"page\"],\n","        \"total_pages\": doc[\"total_pages\"],\n","        'content': doc['content']\n","    }\n","    id_ = doc[\"subject\"] + \"_\" + str(i)\n","    embedding = embeddings.embed_query(doc[\"content\"])\n","    vc = {\n","        'id': id_,\n","        'values': embedding,\n","        'metadata': metadata\n","    }\n","\n","    vector_list.append(vc)\n","\n","  index.upsert(vectors=vector_list, namespace=namespace)\n","\n","\n","\n","store_embeddings(docs=transformer_pre_processed_docs, namespace=\"Transformer\")\n","store_embeddings(docs=seq2seq_pre_processed_docs, namespace=\"Seq2Seq\")"],"metadata":{"id":"Pz8_D-Wq83av"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z46ghY0_AjMt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Create Retriever (Using LangChain):**"],"metadata":{"id":"zW5-Ph-WF-FA"}},{"cell_type":"code","source":["!pip install pinecone-client langchain -qU"],"metadata":{"id":"pPqdvuprFPv7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728999052494,"user_tz":-330,"elapsed":5676,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"4206ad10-26e0-4b64-89f9-5f7656572871"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Configure Pinecone:\n","\n","import os\n","from pinecone import Pinecone\n","\n","# Initialize the Pinecone client\n","pc = Pinecone(\n","    api_key=\"pinecone-api-key\",  # Set your API key in an environment variable\n","    environment=\"us-east-1\"   # Set your Pinecone environment\n",")\n","\n","\n","index = pc.Index(\"test\")\n","index.describe_index_stats()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8r8OOcAWVud","executionInfo":{"status":"ok","timestamp":1728999225488,"user_tz":-330,"elapsed":634,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"b34e7320-0b66-4954-b212-beee4e23a893"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.0,\n"," 'namespaces': {'Seq2Seq': {'vector_count': 9},\n","                'Transformer': {'vector_count': 58}},\n"," 'total_vector_count': 67}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Create retriever:\n","\n","def create_retriever(query, namespace, top_k=5):\n","  query_embedding = embedding_model.embed_query(query)\n","  search_results = index.query(\n","        vector=query_embedding,\n","        top_k=top_k,\n","        namespace=namespace,\n","        include_metadata=True\n","    )\n","  return search_results['matches']\n","\n","\n","create_retriever(query='what is Transformer', namespace='Transformer', top_k=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XmVuq99WVzd","executionInfo":{"status":"ok","timestamp":1728999422984,"user_tz":-330,"elapsed":551,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"8c28a5bd-a783-46a6-f47b-9a88a9e95720"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'id': 'Transformer_12',\n","  'metadata': {'content': 'Figure4: '\n","                          'ProportionoftransformerapplicationinTop-5fields '\n","                          'analysisidentifiedseveralhighlyimpactfulandsignificanttransformer-basedmodelsthathavebeensuccessfullyappliedina '\n","                          'varietyoffields. '\n","                          'Wethenorganizedthesemodelsintofivedifferentapplicationareas: '\n","                          'NaturalLanguageProcessing(NLP), '\n","                          'ComputerVision,Multi-modality,AudioandSpeech,andSignalProcessing. '\n","                          'TheproposedtaxonomyinFigure5providesa '\n","                          'morenuancedandcomprehensiveframeworkforunderstandingthediverseapplicationsoftransformers. '\n","                          'Webelievethatthis '\n","                          'taxonomywouldbebeneficialforresearchersandpractitionersworkingontransformer-basedmodels,asitwouldhelpthem '\n","                          'toidentifythemostrelevantmodelsandtechniquesfortheirspecificapplications. '\n","                          '6.1 NATURALLANGUAGEPROCESSING(NLP) Transformers have '\n","                          'become a vital tool in NLP, and various NLP tasks '\n","                          'have largely benefited from these models. Our pro- '\n","                          'posed taxonomy focuses on NLP and organizes '\n","                          'transformer models into seven popular NLP tasks, '\n","                          'including Translation, Summarization, '\n","                          'ClassificationandSegmentation, QuestionAnswering, '\n","                          'TextGeneration, NaturalLanguageReasoning, and '\n","                          'Automated Symbolic Reasoning. To ensure a '\n","                          'comprehensive analysis, we only considered '\n","                          'transformer models that have significantly impacted '\n","                          'the NLP field and improved its performance. Our '\n","                          'analysis included an in-depth discussion of each '\n","                          'NLPtask,alongwithessentialinformationabouteachmodelpresentedinTable3. '\n","                          'Wealsohighlightedthesignificanceand '\n","                          'workingmethodsofeachmodel. '\n","                          'Thistaxonomyprovidesavaluableframeworkforunderstandingthedifferenttransformer '\n","                          'models used in NLP and their practical applications. '\n","                          'It can help researchers and practitioners select the '\n","                          'most appropriate '\n","                          'transformermodelfortheirspecificNLPtask. 6.1.1 '\n","                          'LANGUAGETRANSLATION '\n","                          'LanguagetranslationisafundamentaltaskinNLP,aimedatconvertinginputtextfromonelanguagetoanother. '\n","                          'Itsprimary objective is to produce an output text '\n","                          'that accurately reflects the meaning of the source '\n","                          'text in the desired language. For example, given an '\n","                          'English sentence as input text, the task aims to '\n","                          'produce its equivalent in French or any other '\n","                          'desired language. '\n","                          'Theoriginaltransformermodelwasdevelopedexplicitlyforthepurposeoflanguagetranslation,highlightingthe '\n","                          'significanceofthistaskintheNLPfield. '\n","                          'Table3identifiesthetransformer-basedmodelsthathavedemonstratedsignificant '\n","                          'performance in the Language Translation task. These '\n","                          'models play a vital role in facilitating effective '\n","                          'communication and '\n","                          'collaborationacrossdifferentlanguages,enablingmoreefficientinformationexchangeandknowledgesharing. '\n","                          'Overall,the '\n","                          'languagetranslationtaskrepresentsacrucialareaofresearchinNLP,withsignificantimplicationsfordiverseapplications, '\n","                          'including business, science, education, and social '\n","                          'interactions. The transformer-based models presented '\n","                          'in the table offer promising solutions for advancing '\n","                          'the state-of-the-art in this field, paving the way '\n","                          'for new and innovative approaches to '\n","                          'languagetranslation(Chowdhary&Chowdhary,2020,Monroe,2017,Hirschberg&Manning,2015).',\n","               'page': 12.0,\n","               'source': 'Research Paper Transformer.pdf',\n","               'subject': 'Transformer',\n","               'total_pages': 58.0},\n","  'score': 0.550165832,\n","  'values': []}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"lzQVLl-KYpXH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Integrate with LLM:**"],"metadata":{"id":"t-69sEJXZ7V4"}},{"cell_type":"markdown","source":["### **Create 2 separate retriever:**"],"metadata":{"id":"ae2Qi5X7b-6n"}},{"cell_type":"code","source":["import os\n","\n","os.environ[\"PINECONE_API_KEY\"] = \"pinecone-api-key\""],"metadata":{"id":"WTvtX7p8YpZO","executionInfo":{"status":"ok","timestamp":1729000022560,"user_tz":-330,"elapsed":712,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from langchain.vectorstores import Pinecone as PineconeVectorStore\n","\n","vectorstore_transformer = PineconeVectorStore.from_existing_index(\n","    index_name='test',\n","    embedding=embedding_model,\n","    text_key=\"content\",\n","    namespace=\"Transformer\"  # Replace with your namespace\n",")\n","\n","vectorstore_seq2seq = PineconeVectorStore.from_existing_index(\n","    index_name='test',\n","    embedding=embedding_model,\n","    text_key=\"content\",\n","    namespace=\"Seq2Seq\"  # Replace with your namespace\n",")"],"metadata":{"id":"CNqoUMYeYpbz","executionInfo":{"status":"ok","timestamp":1729000081583,"user_tz":-330,"elapsed":561,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["vectorstore_transformer.similarity_search(\n","    query=\"what is Transformer\",\n","    k=2\n",")"],"metadata":{"id":"8kHMqwgZYpeU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **LLM Generation:**"],"metadata":{"id":"wNduuddCcDg6"}},{"cell_type":"code","source":["!pip install langchain_google_genai -qU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlUGzqMwbxq5","executionInfo":{"status":"ok","timestamp":1729000224335,"user_tz":-330,"elapsed":12052,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"3d7c8f76-49b9-4db8-b87c-3ad3fd78f51d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/760.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","\n","GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-pro\",\n","    google_api_key=GEMINI_API_KEY,\n","    temperature=0.5,\n","    max_tokens=1024,\n","    max_length=1024,\n",")"],"metadata":{"id":"mfcaMlYacI8s","executionInfo":{"status":"ok","timestamp":1729000390359,"user_tz":-330,"elapsed":2185,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","from IPython.display import display, Markdown\n","\n","\n","prompt = \"\"\"\n","You are an AI-powered virtual assistant, your name is 'Dibyendu', designed by Dibyendu Biswas, who is an AI Engineer.\n","Your task is to answer based on user's query in detailed way.\n","Use the following pieces of context to answer the question at the end.\n","If you don't know the answer, just say that 'I don't have enough information to answer this question'.\n","Provide only the helpful answer. Do not include any other information.\n","\n","Whenever people ask the generaal question you must answer it as well, like:\n","Question: Hi\n","Answer: Hello! How can I assist you with your studies today?\n","\n","Question: What is your name?\n","Answer: I am Dibyendu, your virtual assistant designed by Dibyendu Biswas, an AI Engineer.\n","\n","Context: `{context}`\n","Question: `{question}`\n","\"\"\"\n","\n","prompt_template = PromptTemplate(\n","    template=prompt,\n","    input_variables=['context', 'question']\n",")\n","\n","\n","def generation(vectorstore, query, llm=llm):\n","  qa_chain = RetrievalQA.from_chain_type(\n","      llm=llm,\n","      chain_type=\"stuff\",\n","      retriever=vectorstore.as_retriever(),\n","      chain_type_kwargs={\"prompt\": prompt_template}\n","  )\n","\n","  response = qa_chain.invoke(query)\n","  res = display(Markdown(response['result']))\n","\n","  return res"],"metadata":{"id":"ug6Uwgl8cI-b","executionInfo":{"status":"ok","timestamp":1729000441813,"user_tz":-330,"elapsed":881,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["generation(vectorstore=vectorstore_transformer, query=\"Tell me something about Transformer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"A7wOi5mycJA9","executionInfo":{"status":"ok","timestamp":1729000484030,"user_tz":-330,"elapsed":3692,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"4dfca222-2b6d-44f3-bbe0-b17645b518e4"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Transformers are a type of deep neural network (DNNs) that offer a solution to the limitations of sequence-to-sequence (seq-2-seq) architectures, including short-term dependency of sequence inputs and the sequential processing of input, which hinders parallel training of networks. Transformers leverage the multi-head self-attention mechanism to extract features, and they exhibit great potential for application in NLP."},"metadata":{}}]},{"cell_type":"code","source":["generation(vectorstore=vectorstore_seq2seq, query=\"Tell me something about Sequence to Sequence Learning\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"ZLZV04NJdUc9","executionInfo":{"status":"ok","timestamp":1729000536217,"user_tz":-330,"elapsed":3338,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"a59307d5-e779-4cac-efb2-02e18daac87b"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Sequence to Sequence Learning is a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. It uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector."},"metadata":{}}]},{"cell_type":"code","source":["generation(vectorstore=vectorstore_seq2seq, query=\"What kind of information you have about Sequence to Sequence Learning\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"id":"PbvMtYr8dpeJ","executionInfo":{"status":"ok","timestamp":1729000588411,"user_tz":-330,"elapsed":5065,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"8b5337cf-02e0-4924-b8de-b58d7548bd9b"},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"I have the following information about Sequence to Sequence Learning:\n\n1. Sequence to Sequence Learning is a type of machine learning task that involves learning to map an input sequence to an output sequence.\n\n2. The input and output sequences can be of different lengths, and the mapping can be complex and non-monotonic.\n\n3. Sequence to Sequence Learning is used in a variety of applications, including machine translation, speech recognition, and question answering.\n\n4. The most common approach to Sequence to Sequence Learning is to use a recurrent neural network (RNN), such as a Long Short-Term Memory (LSTM) network.\n\n5. RNNs are able to learn long-term dependencies between elements in the input and output sequences.\n\n6. Sequence to Sequence Learning is a challenging task, but it has made significant progress in recent years.\n\n7. The best performing Sequence to Sequence models are now able to achieve state-of-the-art results on a variety of tasks."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"qaH9ZIGEdguK"},"execution_count":null,"outputs":[]}]}