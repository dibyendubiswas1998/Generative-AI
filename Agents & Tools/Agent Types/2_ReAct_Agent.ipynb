{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMIuqiugKsxUt3aJrLybZR0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ReAct (Reasoning and Acting) Agent:**\n","\n","\n","The **ReAct agent** combines **reasoning** (verbal thought generation) and **acting** (executing task-specific actions) to solve tasks iteratively. Unlike traditional methods that separate reasoning and tool usage, ReAct tightly integrates these two steps, enabling more accurate and grounded decision-making.<br><br>\n","\n","**Working Principal:**<br>\n","1. **Reasoning:** The model generates logical steps (thoughts) to plan actions.\n","2. **Action:** The model interacts with tools (e.g., search APIs) to gather external information.\n","3. **Observation:** Results are processed, and reasoning continues based on new insights.\n","4. **Iteration:** This cycle repeats until the task is solved.\n","\n"],"metadata":{"id":"Nl1pRwatfS1J"}},{"cell_type":"code","source":["# install necessary libaries:\n","\n","%pip install --upgrade --quiet sentence_transformers\n","%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-google-genai langchain-chroma bs4 boto3\n","%pip install --upgrade --quiet langchain-aws wikipedia youtube-search tavily-python"],"metadata":{"id":"1VtP8mv7fBQV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load LLM:**"],"metadata":{"id":"dK_XwfXyhwuT"}},{"cell_type":"code","source":["# Load the Tokens:\n","\n","from google.colab import userdata\n","import os\n","\n","os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')\n","os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n","os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')"],"metadata":{"id":"KdZx34x9iCIA","executionInfo":{"status":"ok","timestamp":1734674101259,"user_tz":-330,"elapsed":4802,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-pro\",\n","    temperature=0.4,\n","    max_tokens=512,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")\n","\n","print(llm.invoke(\"hi\").content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXuSMudyhzVV","executionInfo":{"status":"ok","timestamp":1734674101927,"user_tz":-330,"elapsed":669,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"c7adff4a-c803-41eb-b3bb-463543aaaae1"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi there! How can I help you today?\n","\n"]}]},{"cell_type":"markdown","source":["## **Load Embeddings from HF:**"],"metadata":{"id":"7q_u4LiGhzpH"}},{"cell_type":"code","source":["%pip install --upgrade tokenizers"],"metadata":{"id":"yhzXAlmrjBp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the Embeddings:\n","\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","embeddings = HuggingFaceEmbeddings(model_name=model_name)"],"metadata":{"id":"vLX25A9VfBSu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Vector Store:**"],"metadata":{"id":"ftIrHS2Ih9ck"}},{"cell_type":"code","source":["import bs4\n","from langchain import hub\n","from langchain_chroma import Chroma\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aVLVbFhfBVO","executionInfo":{"status":"ok","timestamp":1734672889748,"user_tz":-330,"elapsed":1998,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"8aceb010-3058-41c1-e998-c8b70891d33d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}]},{"cell_type":"code","source":["# Load, chunk and index the contents of the blog.\n","loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n","docs = loader.load()\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(docs)\n","vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"],"metadata":{"id":"SKoq1SqWfBXu","executionInfo":{"status":"ok","timestamp":1734672892621,"user_tz":-330,"elapsed":2875,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# retriever:\n","\n","retriever = vectorstore.as_retriever(search_kwargs=dict(k=5))"],"metadata":{"id":"7fEE7JUGfBaX","executionInfo":{"status":"ok","timestamp":1734672892621,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["retriever.get_relevant_documents(\"what is langchain?\")"],"metadata":{"id":"BXQ2v3RVfBcx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Implementation of ReAct Agent:**"],"metadata":{"id":"H-het437kUdo"}},{"cell_type":"markdown","source":["### **Example 01: Simple implementation**"],"metadata":{"id":"uTnD_u-ckaP7"}},{"cell_type":"code","source":["from langchain import hub\n","from langchain.agents import AgentExecutor, create_react_agent\n","from langchain_community.tools.tavily_search import TavilySearchResults"],"metadata":{"id":"K58ADRxYfBfK","executionInfo":{"status":"ok","timestamp":1734673044178,"user_tz":-330,"elapsed":646,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# initialized the Tool:\n","\n","tools = [TavilySearchResults(max_results=5)]"],"metadata":{"id":"asC88eRzfBhs","executionInfo":{"status":"ok","timestamp":1734673066351,"user_tz":-330,"elapsed":581,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Get the prompt to use - you can modify this!\n","prompt = hub.pull(\"hwchase17/react\")\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOwWUrIWfBkg","executionInfo":{"status":"ok","timestamp":1734673082106,"user_tz":-330,"elapsed":437,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"1a786206-de65-4f1f-8a38-578b509d5c28"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Construct the ReAct agent\n","agent = create_react_agent(llm, tools, prompt)"],"metadata":{"id":"8-dgB_oJfBm8","executionInfo":{"status":"ok","timestamp":1734673095964,"user_tz":-330,"elapsed":405,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Create an agent executor by passing in the agent and tools\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"],"metadata":{"id":"7U4FFq-qktja","executionInfo":{"status":"ok","timestamp":1734673108672,"user_tz":-330,"elapsed":425,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["agent_executor.invoke({\"input\": \"what is LangChain?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ka9rjj_Ukt9V","executionInfo":{"status":"ok","timestamp":1734673118894,"user_tz":-330,"elapsed":8694,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"81b3305a-0e80-4bf2-bb58-a58eb1e7aa59"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mQuestion: what is LangChain?\n","Thought: I need to search for information about LangChain.  I can use the tavily_search_results_json tool for this.\n","Action: tavily_search_results_json\n","Action Input: \"What is LangChain?\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.geeksforgeeks.org/introduction-to-langchain/', 'content': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.'}, {'url': 'https://python.langchain.com/docs/introduction/', 'content': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}, {'url': 'https://www.langchain.com/langchain', 'content': 'Augment the power\\nof\\xa0LLMs with your data\\nLangChain helps connect LLMs to your company’s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChain’s flexible abstractions and AI-first toolkit make it\\xa0the\\xa0#1\\xa0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\xa0gives\\xa0you choice, flexibility, and power as\\xa0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.'}, {'url': 'https://www.techtarget.com/searchEnterpriseAI/definition/LangChain', 'content': \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}, {'url': 'https://datasciencedojo.com/blog/what-is-langchain/', 'content': 'LangChain stands out by simplifying the development and deployment of LLM-powered applications, making it easier for businesses to integrate advanced AI capabilities into their processes. By integrating LLMs with real-time data and external knowledge bases, LangChain empowers businesses to create more sophisticated and responsive AI applications, driving innovation and improving service delivery across various sectors. From modular components that simplify complex tasks to advanced prompt engineering and seamless integration with external data sources, LangChain offers everything developers need to build powerful, intelligent applications. LangChain provides a set of tools and components that help integrate LLMs with other data sources and computation tools, making it easier to build sophisticated AI applications like chatbots, content generators, and data retrieval systems.'}]\u001b[0m\u001b[32;1m\u001b[1;3mI have enough information to answer the question.\n","Final Answer: LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It allows developers to connect LLMs to other data sources and computational tools, enabling the development of more complex and context-aware applications.  Key features and functionalities include: chains (sequences of calls to LLMs or other utilities), agents (dynamically select which tools to use based on user input), indexes (structure documents for LLMs to use), and memory (persist application state between runs of a chain).  It's used to build applications like chatbots, question-answering systems, and summarization tools.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'what is LangChain?',\n"," 'output': \"LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It allows developers to connect LLMs to other data sources and computational tools, enabling the development of more complex and context-aware applications.  Key features and functionalities include: chains (sequences of calls to LLMs or other utilities), agents (dynamically select which tools to use based on user input), indexes (structure documents for LLMs to use), and memory (persist application state between runs of a chain).  It's used to build applications like chatbots, question-answering systems, and summarization tools.\"}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["### **Example 02: From Databse**"],"metadata":{"id":"W970vwvjnIek"}},{"cell_type":"code","source":["from langchain.tools import tool\n","from langchain import hub"],"metadata":{"id":"UA9S1zV3kuAC","executionInfo":{"status":"ok","timestamp":1734674108874,"user_tz":-330,"elapsed":459,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Custom tool for the Agent\n","@tool\n","def get_employee_id(name):\n","  \"\"\"\n","  To get employee id, it takes employee name as arguments\n","  name(str): Name of the employee\n","  \"\"\"\n","  employees_name = {\n","    \"Alice\": \"E001\",\n","    \"Bob\": \"E002\",\n","    \"Charlie\": \"E003\",\n","    \"Diana\": \"E004\",\n","    \"Evan\": \"E005\",\n","    \"Fiona\": \"E006\",\n","    \"George\": \"E007\",\n","    \"Hannah\": \"E008\",\n","    \"Ian\": \"E009\",\n","    \"Jasmine\": \"E010\"}\n","\n","  return employees_name.get(name, \"Employee not found\")\n","\n","\n","\n","# Custom tool for the Agent\n","@tool\n","def get_employee_salary(employee_id):\n","  \"\"\"\n","  To get the salary of an employee, it takes employee_id as input and return salary\n","  \"\"\"\n","  employee_salaries = {\n","    \"E001\": 56000,\n","    \"E002\": 47000,\n","    \"E003\": 52000,\n","    \"E004\": 61000,\n","    \"E005\": 45000,\n","    \"E006\": 58000,\n","    \"E007\": 49000,\n","    \"E008\": 53000,\n","    \"E009\": 50000,\n","    \"E010\": 55000\n","    }\n","  return employee_salaries.get(employee_id,\"Employee not found\")\n","\n","\n","# Get the Tools:\n","tools = [get_employee_salary, get_employee_id]"],"metadata":{"id":"-8TR2kpGkuCe","executionInfo":{"status":"ok","timestamp":1734674109314,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Define the Prompt:\n","prompt = hub.pull(\"hwchase17/react\")\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1FblgeukuFE","executionInfo":{"status":"ok","timestamp":1734674112482,"user_tz":-330,"elapsed":439,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"abf216c0-57ee-4f0d-ae14-960558be709e"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Create Agent:\n","agent = create_react_agent(llm, tools, prompt)"],"metadata":{"id":"LqjaTBdAnn8q","executionInfo":{"status":"ok","timestamp":1734674115245,"user_tz":-330,"elapsed":407,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Call the Agent Executor:\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"],"metadata":{"id":"CjuRLQesnxDp","executionInfo":{"status":"ok","timestamp":1734674116403,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["agent_executor.invoke({\"input\":\"What is the Salary and Employee Id of Fiona?\"})"],"metadata":{"id":"gOYYXT4snxGM","executionInfo":{"status":"ok","timestamp":1734674515685,"user_tz":-330,"elapsed":483,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rHDZmiLSnxIi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Example 03: Use Chat History**"],"metadata":{"id":"csS7txuIqRub"}},{"cell_type":"markdown","source":["#### **Create Memory:**"],"metadata":{"id":"sNyiO6hwuCxH"}},{"cell_type":"code","source":["from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory"],"metadata":{"id":"hHZyu-LtrlUH","executionInfo":{"status":"ok","timestamp":1734675563292,"user_tz":-330,"elapsed":430,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# store the session information in message_history:\n","\n","message_history = ChatMessageHistory()\n","message_history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zq960irt4qD","executionInfo":{"status":"ok","timestamp":1734675563998,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"d38cda4f-284b-4d62-a33d-3e26d578d91f"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InMemoryChatMessageHistory(messages=[])"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["#### **Create Agent:**"],"metadata":{"id":"1yxHenQuuJ_r"}},{"cell_type":"code","source":["from langchain import hub\n","from langchain.agents import AgentExecutor, create_react_agent\n","from langchain_community.tools.tavily_search import TavilySearchResults"],"metadata":{"id":"KF06nmF4t4sR","executionInfo":{"status":"ok","timestamp":1734675590443,"user_tz":-330,"elapsed":524,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Create RAG Tool:\n","\n","from langchain.tools.retriever import create_retriever_tool\n","\n","\n","retriever_tool = create_retriever_tool(\n","    retriever=retriever,\n","    name=\"langsmith_search\",\n","    description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\"\n",")"],"metadata":{"id":"5UVMZbJJt4ur","executionInfo":{"status":"ok","timestamp":1734675620016,"user_tz":-330,"elapsed":552,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["tools = [TavilySearchResults(max_results=1), retriever_tool]"],"metadata":{"id":"PUw3aV9bt4w_","executionInfo":{"status":"ok","timestamp":1734675630798,"user_tz":-330,"elapsed":442,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Define The Prompt:\n","\n","# Get the prompt to use - you can modify this!\n","prompt = hub.pull(\"hwchase17/react-chat\")\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-75xGK7uYPD","executionInfo":{"status":"ok","timestamp":1734675660426,"user_tz":-330,"elapsed":436,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"291e5bec-26c8-49a8-fcee-8278f489b890"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react-chat', 'lc_hub_commit_hash': '3ecd5f710db438a9cf3773c57d6ac8951eefd2cd9a9b2a0026a65a0893b86a6e'}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n{tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}')"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["# Construct the ReAct agent:\n","\n","agent = create_react_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"],"metadata":{"id":"UInh8PbcuYsf","executionInfo":{"status":"ok","timestamp":1734675670043,"user_tz":-330,"elapsed":451,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["agent_executor.invoke(\n","    {\n","        \"input\": \"what is langchain?\",\n","        \"chat_history\": message_history.messages\n","    }\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkF7QlK-uYvC","executionInfo":{"status":"ok","timestamp":1734675725135,"user_tz":-330,"elapsed":4522,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"173350a5-5e36-4f34-8063-842862359911"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n","Action: langsmith_search\n","Action Input: What is LangChain?\u001b[0m\u001b[33;1m\u001b[1;3mLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n","LangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\n","In this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\n","1. Install LangSmith‚Äã\n","PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","\n","Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n","and explore the results of your evaluation.\n","Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n","Was this page helpful?You can leave detailed feedback on GitHub.NextObservability tutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\n","\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\n","4. Log your first trace‚Äã\n","We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n","how to use traceable(). See more on the Annotate code for tracing page.\n","\n","Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n","\n","\n","\n","\n","\n","\n","Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\n","LangSmith is a platform for building production-grade LLM applications.\n","It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n","With LangSmith you can:\n","\n","PythonTypeScriptfrom langsmith import Client, traceableclient = Client()# Define dataset: these are your test casesdataset = client.create_dataset(    \"Sample Dataset\",    description=\"A sample dataset in LangSmith.\",)client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"response\": \"Welcome to LangSmith\"},        {\"response\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define an interface to your application (tracing optional)@traceabledef dummy_app(inputs: dict) -> dict:    return {\"response\": \"Welcome \" + inputs[\"postfix\"]}# Define your evaluator(s)def exact_match(outputs: dict, reference_outputs: dict) -> bool:    return outputs[\"response\"] == reference_outputs[\"response\"]# Run the evaluationexperiment_results = client.evaluate(    dummy_app, # Your AI system goes here    data=dataset, # The data to predict and grade over    evaluators=[exact_match], # The\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n","Final Answer: LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured information.  It also simplifies the management of prompts and chains of prompts, making it easier to create complex language model workflows.  While LangSmith integrates with LangChain for enhanced observability and evaluation, they are distinct entities.  LangChain focuses on building the applications, while LangSmith helps monitor and improve their performance.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'what is langchain?',\n"," 'chat_history': [],\n"," 'output': 'LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured information.  It also simplifies the management of prompts and chains of prompts, making it easier to create complex language model workflows.  While LangSmith integrates with LangChain for enhanced observability and evaluation, they are distinct entities.  LangChain focuses on building the applications, while LangSmith helps monitor and improve their performance.'}"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["#### **Add Conversation into Memory Dynamically using Session:**"],"metadata":{"id":"4d9gOPEdu3DD"}},{"cell_type":"code","source":["# Agent Executor with Memory:\n","\n","agent_with_chat_history = RunnableWithMessageHistory(\n","    agent_executor,\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    lambda session_id: message_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")"],"metadata":{"id":"ZhKqbt94uYxh","executionInfo":{"status":"ok","timestamp":1734675812961,"user_tz":-330,"elapsed":434,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["#### **Start Interaction:**"],"metadata":{"id":"S4UHFnJEvMDz"}},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET4kEf_9uYz1","executionInfo":{"status":"ok","timestamp":1734675818675,"user_tz":-330,"elapsed":2786,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"bb7c0ff6-0828-48ec-be27-c63a9a35a6d9"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n","Final Answer: Hi Dibyendu! I understand you're an AI/ML Engineer and currently looking for a job. That can be a tough situation.  I'm here to help if I can. Is there anything specific you'd like to talk about or get assistance with?  For example, are you looking for advice on your resume, interview tips, or help finding job postings?\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': \"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\",\n"," 'chat_history': [],\n"," 'output': \"Hi Dibyendu! I understand you're an AI/ML Engineer and currently looking for a job. That can be a tough situation.  I'm here to help if I can. Is there anything specific you'd like to talk about or get assistance with?  For example, are you looking for advice on your resume, interview tips, or help finding job postings?\"}"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"What is LangChain?\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftSCZBp9uY2F","executionInfo":{"status":"ok","timestamp":1734675871808,"user_tz":-330,"elapsed":3905,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"f9cba532-eead-493b-baef-a3dce82d2db4"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n","Action: langsmith_search\n","Action Input: What is LangChain?\u001b[0m\u001b[33;1m\u001b[1;3mLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n","LangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\n","In this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\n","1. Install LangSmith‚Äã\n","PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","\n","Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n","and explore the results of your evaluation.\n","Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n","Was this page helpful?You can leave detailed feedback on GitHub.NextObservability tutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\n","\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\n","4. Log your first trace‚Äã\n","We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n","how to use traceable(). See more on the Annotate code for tracing page.\n","\n","Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n","\n","\n","\n","\n","\n","\n","Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\n","LangSmith is a platform for building production-grade LLM applications.\n","It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n","With LangSmith you can:\n","\n","PythonTypeScriptfrom langsmith import Client, traceableclient = Client()# Define dataset: these are your test casesdataset = client.create_dataset(    \"Sample Dataset\",    description=\"A sample dataset in LangSmith.\",)client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"response\": \"Welcome to LangSmith\"},        {\"response\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define an interface to your application (tracing optional)@traceabledef dummy_app(inputs: dict) -> dict:    return {\"response\": \"Welcome \" + inputs[\"postfix\"]}# Define your evaluator(s)def exact_match(outputs: dict, reference_outputs: dict) -> bool:    return outputs[\"response\"] == reference_outputs[\"response\"]# Run the evaluationexperiment_results = client.evaluate(    dummy_app, # Your AI system goes here    data=dataset, # The data to predict and grade over    evaluators=[exact_match], # The\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n","Final Answer: LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured data.  It also provides modules for managing prompts, chains for sequencing calls to LLMs or other utilities, and agents to decide which actions to take.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is LangChain?',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"Hi Dibyendu! I understand you're an AI/ML Engineer and currently looking for a job. That can be a tough situation.  I'm here to help if I can. Is there anything specific you'd like to talk about or get assistance with?  For example, are you looking for advice on your resume, interview tips, or help finding job postings?\", additional_kwargs={}, response_metadata={})],\n"," 'output': 'LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured data.  It also provides modules for managing prompts, chains for sequencing calls to LLMs or other utilities, and agents to decide which actions to take.'}"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"Who is Dibyendu?\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yp3HoX5XvSY7","executionInfo":{"status":"ok","timestamp":1734675917220,"user_tz":-330,"elapsed":2001,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"6a519433-6bfb-48fb-d760-707838bab45d"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n","Final Answer: You told me you are Dibyendu, an AI/ML Engineer looking for a job.  Is there anything else I can tell you about yourself based on what you've shared with me?\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Who is Dibyendu?',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"Hi Dibyendu! I understand you're an AI/ML Engineer and currently looking for a job. That can be a tough situation.  I'm here to help if I can. Is there anything specific you'd like to talk about or get assistance with?  For example, are you looking for advice on your resume, interview tips, or help finding job postings?\", additional_kwargs={}, response_metadata={}),\n","  HumanMessage(content='What is LangChain?', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content='LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured data.  It also provides modules for managing prompts, chains for sequencing calls to LLMs or other utilities, and agents to decide which actions to take.', additional_kwargs={}, response_metadata={})],\n"," 'output': \"You told me you are Dibyendu, an AI/ML Engineer looking for a job.  Is there anything else I can tell you about yourself based on what you've shared with me?\"}"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["message_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfYgDpyNvdp2","executionInfo":{"status":"ok","timestamp":1734675979367,"user_tz":-330,"elapsed":457,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"b5ca89ee-53e1-4ad6-aa47-88f8e4b398b0"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}),\n"," AIMessage(content=\"Hi Dibyendu! I understand you're an AI/ML Engineer and currently looking for a job. That can be a tough situation.  I'm here to help if I can. Is there anything specific you'd like to talk about or get assistance with?  For example, are you looking for advice on your resume, interview tips, or help finding job postings?\", additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='What is LangChain?', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='LangChain is a framework designed for developing applications powered by language models. It offers a streamlined process for connecting a language model to various data sources, enabling tasks like chatting with documents, querying APIs, and extracting structured data.  It also provides modules for managing prompts, chains for sequencing calls to LLMs or other utilities, and agents to decide which actions to take.', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='Who is Dibyendu?', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content=\"You told me you are Dibyendu, an AI/ML Engineer looking for a job.  Is there anything else I can tell you about yourself based on what you've shared with me?\", additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='Who is Dibyendu?', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content=\"You told me you are Dibyendu, an AI/ML Engineer looking for a job.  Is there anything else I can tell you about yourself based on what you've shared with me?\", additional_kwargs={}, response_metadata={})]"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":[],"metadata":{"id":"9QRF_uW1vi7f"},"execution_count":null,"outputs":[]}]}