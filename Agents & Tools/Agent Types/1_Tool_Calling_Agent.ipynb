{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIKdDTuTD1m7/5y6jLLhSb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Tool Calling Agent:**\n","\n","Tool calling allows a model to detect when one or more tools should be called and respond with the inputs that should be passed to those tools. In an API call, you can describe tools and have the model intelligently choose to output a structured object like JSON containing arguments to call these tools. The goal of tools APIs is to more reliably return valid and useful tool calls than what can be done using a generic text completion or chat API.<br>\n","\n","We can take advantage of this structured output, combined with the fact that <u>you can **bind multiple tools to a tool calling chat model and allow the model to choose which one to call**, to create an agent that repeatedly calls tools and receives results until a query is resolved.</u><br><br>\n","\n","<u>Tool Calling is an agent type where an LLM decides **which tools to call** (based on user query), **what inputs to provide**, and how to process results to achieve a task. Tools include APIs, search engines, or calculators.</u>"],"metadata":{"id":"q9ZwDcEwZYyg"}},{"cell_type":"code","source":["# install necessary libaries:\n","\n","%pip install --upgrade --quiet sentence_transformers\n","%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-google-genai langchain-chroma bs4 boto3\n","%pip install --upgrade --quiet langchain-aws wikipedia youtube-search tavily-python"],"metadata":{"id":"KES7j5VghJEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load LLM & Embeddings::**"],"metadata":{"id":"oPaflv7Whzir"}},{"cell_type":"code","source":["# Load the Tokens:\n","\n","from google.colab import userdata\n","import os\n","\n","os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')\n","os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"],"metadata":{"id":"nbR3JG7Khy1V","executionInfo":{"status":"ok","timestamp":1734521389192,"user_tz":-330,"elapsed":8059,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-pro\",\n","    temperature=0.4,\n","    max_tokens=512,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")\n","\n","print(llm.invoke(\"hi\").content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mfdMPIUhy4F","executionInfo":{"status":"ok","timestamp":1734521539208,"user_tz":-330,"elapsed":80817,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"08804222-8ec8-4ac4-bc62-18ad133248b7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi there! How can I help you today?\n","\n"]}]},{"cell_type":"markdown","source":["## **Load Embedding from HF:**"],"metadata":{"id":"HCUociHliEGu"}},{"cell_type":"code","source":["# Get the Embeddings:\n","\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","embeddings = HuggingFaceEmbeddings(model_name=model_name)"],"metadata":{"id":"JjP4CpSNiDuj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Vector Store:**"],"metadata":{"id":"vdC0vFseiJku"}},{"cell_type":"code","source":["import bs4\n","from langchain import hub\n","from langchain_chroma import Chroma\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdKl5PHtiDxL","executionInfo":{"status":"ok","timestamp":1734521594905,"user_tz":-330,"elapsed":1537,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"3e2d49ea-dde2-443b-9792-2f3ee84b485b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}]},{"cell_type":"code","source":["# Load, chunk and index the contents of the blog.\n","loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n","docs = loader.load()\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(docs)\n","vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"],"metadata":{"id":"QL4HOjX3hzEI","executionInfo":{"status":"ok","timestamp":1734521658023,"user_tz":-330,"elapsed":2855,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# retriever:\n","\n","retriever = vectorstore.as_retriever(search_kwargs=dict(k=5))"],"metadata":{"id":"pVcLwpEMiOlg","executionInfo":{"status":"ok","timestamp":1734521661773,"user_tz":-330,"elapsed":427,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["retriever.get_relevant_documents(\"what is langchain?\")"],"metadata":{"id":"o3MXKwgUiOn2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1. Simple Tool Calling Agent:**"],"metadata":{"id":"WjbJDPEDhCmn"}},{"cell_type":"markdown","source":["### **Get The Tool: One Tool**\n","\n","* **Tavily-Search-Results**\n"],"metadata":{"id":"y46pTYUDkUW5"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n","os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"],"metadata":{"id":"NO8Y6JbThCKi","executionInfo":{"status":"ok","timestamp":1734521977659,"user_tz":-330,"elapsed":2249,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Get the Tavily Search Results Tool:\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","\n","search = TavilySearchResults()"],"metadata":{"id":"lnkPY4i4ZTYR","executionInfo":{"status":"ok","timestamp":1734522278230,"user_tz":-330,"elapsed":18,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# use the tool:\n","\n","tools = [search]"],"metadata":{"id":"6RlrtSh5ZTa2","executionInfo":{"status":"ok","timestamp":1734522307504,"user_tz":-330,"elapsed":425,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### **Define the Prompt:**"],"metadata":{"id":"9ufC8gzwlrIl"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant.\",\n","        ),\n","        (\"placeholder\", \"{chat_history}\"),\n","        (\"human\", \"{input}\"),\n","        (\"placeholder\", \"{agent_scratchpad}\"),\n","    ]\n",")\n","\n","\n","prompt"],"metadata":{"id":"rnvHR5igZTdT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Create Agent:**"],"metadata":{"id":"r2PMgFSym110"}},{"cell_type":"code","source":["from langchain.agents import create_tool_calling_agent"],"metadata":{"id":"rCW8HOGuZTf3","executionInfo":{"status":"ok","timestamp":1734522788255,"user_tz":-330,"elapsed":458,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Construct the Tools agent\n","\n","agent = create_tool_calling_agent(llm, tools, prompt)"],"metadata":{"id":"JNtDNOuKZTiQ","executionInfo":{"status":"ok","timestamp":1734522913641,"user_tz":-330,"elapsed":689,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Create an agent executor by passing in the agent and tools\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"],"metadata":{"id":"kqGSsDlnZTk0","executionInfo":{"status":"ok","timestamp":1734522913641,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### **Run the Agent Executor:**"],"metadata":{"id":"1EXfGNtOn7k2"}},{"cell_type":"markdown","source":["**AgentExecutor:**<br>\n","AgentExecutor in LangChain is a component that runs the **agent's logic** **by orchestrating the flow between the LLM, tools, and inputs**. It handles decision-making, tool invocation, and result processing.<br><br>\n","\n","\n","**Key Features:**<br>\n","\n","1. **Takes Input:** Accepts the user query and initial parameters.\n","2. **Execcutes the Agent:** Runs the agent's reasoning logic to select and call tools.\n","3. **Handles Iteration:** Continues until a final response is generated (or a stopping condition is reached).\n","4. **Returns Output:** Provides the final processed response.\n","\n","<br>\n","\n","The **AgentExecutor** ensures smooth coordination of tasks in a multi-tool environment, making agents efficient and reliable."],"metadata":{"id":"pQHYDsW-0Pja"}},{"cell_type":"code","source":["from langchain.agents import AgentExecutor"],"metadata":{"id":"KKRlUVJf0N9D","executionInfo":{"status":"ok","timestamp":1734526168742,"user_tz":-330,"elapsed":425,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Run the Agent:\n","\n","agent_executor.invoke({\"input\": \"what is LangChain?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJB1BioLZTnU","executionInfo":{"status":"ok","timestamp":1734522922954,"user_tz":-330,"elapsed":8778,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"9665e37f-227f-49df-ebc6-4dfae54872e2"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `tavily_search_results_json` with `{'query': 'what is LangChain?'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.geeksforgeeks.org/introduction-to-langchain/', 'content': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.'}, {'url': 'https://python.langchain.com/docs/introduction/', 'content': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}, {'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}, {'url': 'https://js.langchain.com/docs/introduction/', 'content': \"How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools How to pass tool outputs to chat models How to use LangChain tools How to use few-shot prompting with tool calling Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. Use LangGraph.js to build stateful agents with first-class streaming and human-in-the-loop support. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangGraph.js: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}, {'url': 'https://www.techtarget.com/searchEnterpriseAI/definition/LangChain', 'content': \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is an open-source framework for developing applications powered by large language models (LLMs). It simplifies the process of creating LLM-backed applications by providing a standard interface, integrations with various data sources and LLM providers, and pre-built components for common LLM tasks.  It allows developers to connect LLMs to other sources of computation or knowledge, such as APIs or web search. Some key features and concepts include:\n","\n","* **Key Concepts:** Chains, agents, indexes, and callbacks.\n","* **Modules:** Prompt templates, LLMs, document loaders, utilities, chains, agents, indexes, memory, and callbacks.\n","* **Integrations:**  A wide range of integrations with LLM providers (OpenAI, Hugging Face, etc.), data sources (Google Drive, Wikipedia, etc.), and other tools.\n","\n","LangChain is used to build a variety of applications, including chatbots, question-answering systems, text summarization tools, and code analysis tools.  It's a rapidly evolving project with a growing community and ecosystem.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'what is LangChain?',\n"," 'output': \"LangChain is an open-source framework for developing applications powered by large language models (LLMs). It simplifies the process of creating LLM-backed applications by providing a standard interface, integrations with various data sources and LLM providers, and pre-built components for common LLM tasks.  It allows developers to connect LLMs to other sources of computation or knowledge, such as APIs or web search. Some key features and concepts include:\\n\\n* **Key Concepts:** Chains, agents, indexes, and callbacks.\\n* **Modules:** Prompt templates, LLMs, document loaders, utilities, chains, agents, indexes, memory, and callbacks.\\n* **Integrations:**  A wide range of integrations with LLM providers (OpenAI, Hugging Face, etc.), data sources (Google Drive, Wikipedia, etc.), and other tools.\\n\\nLangChain is used to build a variety of applications, including chatbots, question-answering systems, text summarization tools, and code analysis tools.  It's a rapidly evolving project with a growing community and ecosystem.\\n\"}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["agent_executor.invoke({\"input\": \"Hi. How are you\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyaZ27atZTp0","executionInfo":{"status":"ok","timestamp":1734522991743,"user_tz":-330,"elapsed":3169,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"ee7852e7-d49e-4f9c-c707-036144750f96"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI'm doing well, thank you for asking. How can I help you today?\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Hi. How are you',\n"," 'output': \"I'm doing well, thank you for asking. How can I help you today?\\n\"}"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"ERZvN8v2ZTsH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Add Multiple Tools: RAG, YouTube Tools**"],"metadata":{"id":"RLsNJy4iomhA"}},{"cell_type":"markdown","source":["### **Get the Tools:**"],"metadata":{"id":"DtyzLs7tovGr"}},{"cell_type":"markdown","source":["#### **YouTube Search Tool:**"],"metadata":{"id":"s0ivSqgupW4E"}},{"cell_type":"code","source":["# Get the YouTube Search Tool:\n","\n","from langchain_community.tools import YouTubeSearchTool\n","\n","youtube_tool = YouTubeSearchTool()"],"metadata":{"id":"c8AyaufxZTw1","executionInfo":{"status":"ok","timestamp":1734523294856,"user_tz":-330,"elapsed":434,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["#### **Tavily Search Results Tool:**"],"metadata":{"id":"ASKC5E4Bpa7F"}},{"cell_type":"code","source":["# Get the Tavily Search Results Tool:\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","\n","search = TavilySearchResults()"],"metadata":{"id":"ht7-1GnxZTzV","executionInfo":{"status":"ok","timestamp":1734523297912,"user_tz":-330,"elapsed":446,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["#### **RAG Tool:**"],"metadata":{"id":"jtS_rXXapfla"}},{"cell_type":"code","source":["# Get the RAG Tool:\n","\n","from langchain.tools.retriever import create_retriever_tool"],"metadata":{"id":"a-xBWdE3pImA","executionInfo":{"status":"ok","timestamp":1734523389584,"user_tz":-330,"elapsed":446,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["retriever_tool = create_retriever_tool(\n","    retriever=retriever,\n","    name=\"langsmith_search\",\n","    description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\"\n",")"],"metadata":{"id":"vE3D76GmpIoa","executionInfo":{"status":"ok","timestamp":1734523904071,"user_tz":-330,"elapsed":434,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["#### **Get the main tool bycombining all tools:**"],"metadata":{"id":"b9QxhTJtrpA_"}},{"cell_type":"code","source":["tools = [search, retriever_tool, youtube_tool]"],"metadata":{"id":"AUFSY9oSpIq9","executionInfo":{"status":"ok","timestamp":1734523951889,"user_tz":-330,"elapsed":4,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["### **Create or Define Chat Prompt Template:**"],"metadata":{"id":"hwsefQcisTZc"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant.\",\n","        ),\n","        (\"placeholder\", \"{chat_history}\"),\n","        (\"human\", \"{input}\"),\n","        (\"placeholder\", \"{agent_scratchpad}\"),\n","    ]\n",")\n","\n","\n","# prompt"],"metadata":{"id":"FAfjSO7npItS","executionInfo":{"status":"ok","timestamp":1734524114708,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["### **Create Agent:**"],"metadata":{"id":"8G_uZT2tsbcu"}},{"cell_type":"code","source":["from langchain.agents import create_tool_calling_agent, AgentExecutor"],"metadata":{"id":"8DXstk5qr1vc","executionInfo":{"status":"ok","timestamp":1734524140374,"user_tz":-330,"elapsed":636,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["agent = create_tool_calling_agent(llm, tools, prompt)"],"metadata":{"id":"f7hg5Kbor1x1","executionInfo":{"status":"ok","timestamp":1734524148846,"user_tz":-330,"elapsed":428,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["### **Call Agent: For Generating Response**"],"metadata":{"id":"3ZCjKtYPsiYg"}},{"cell_type":"code","source":["from langchain.agents import AgentExecutor\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"],"metadata":{"id":"JrZArqHDr10L","executionInfo":{"status":"ok","timestamp":1734524204246,"user_tz":-330,"elapsed":442,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["agent_executor.invoke({\"input\": \"Hi, how are you?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCpHAzSEr12e","executionInfo":{"status":"ok","timestamp":1734524269208,"user_tz":-330,"elapsed":15403,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"5b339799-1d56-478d-8653-c3a5df8332a3"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI'm doing well, thank you for asking. How can I help you today?\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Hi, how are you?',\n"," 'output': \"I'm doing well, thank you for asking. How can I help you today?\\n\"}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["agent_executor.invoke({\"input\": \"What is LangSmith?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hljJJD19r14z","executionInfo":{"status":"ok","timestamp":1734524367338,"user_tz":-330,"elapsed":59405,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"881a99a4-178a-4ec5-ad89-bd504dca4386"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `langsmith_search` with `{'query': 'What is LangSmith?'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n","\n","\n","\n","\n","\n","\n","Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\n","LangSmith is a platform for building production-grade LLM applications.\n","It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n","With LangSmith you can:\n","\n","LangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n","LangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\n","In this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\n","1. Install LangSmith‚Äã\n","PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","\n","Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n","and explore the results of your evaluation.\n","Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n","Was this page helpful?You can leave detailed feedback on GitHub.NextObservability tutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\n","\n","PythonTypeScriptimport openaifrom langsmith import wrappers, traceable# Auto-trace LLM calls in-contextclient = wrappers.wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-4o-mini\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there!\n","\n","2. Create an API key‚Äã\n","To create an API key head to the Settings page. Then click Create API Key.\n","3. Set up your environment‚Äã\n","Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\n","4. Log your first trace‚Äã\n","We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n","how to use traceable(). See more on the Annotate code for tracing page.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building, testing, evaluating, and deploying large language model (LLM) applications. It integrates with LangChain and provides tools to improve LLM application performance.  It offers features for tracing, debugging, and evaluating LLM workflows. You can find more information in their documentation or on their website.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is LangSmith?',\n"," 'output': 'LangSmith is a platform for building, testing, evaluating, and deploying large language model (LLM) applications. It integrates with LangChain and provides tools to improve LLM application performance.  It offers features for tracing, debugging, and evaluating LLM workflows. You can find more information in their documentation or on their website.\\n'}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["agent_executor.invoke({\"input\": \"Give some video related to LangSmith\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLPARJpMr16-","executionInfo":{"status":"ok","timestamp":1734524947460,"user_tz":-330,"elapsed":532280,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"27acb984-c289-4257-8f07-014c53bc95f7"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `youtube_search` with `{'query': 'LangSmith, 5'}`\n","\n","\n","\u001b[0m\u001b[38;5;200m\u001b[1;3m['https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUJTGFuZ1NtaXRo', 'https://www.youtube.com/watch?v=KcGoJPK-0tY&pp=ygUJTGFuZ1NtaXRo', 'https://www.youtube.com/watch?v=Hab2CV_0hpQ&pp=ygUJTGFuZ1NtaXRo', 'https://www.youtube.com/watch?v=ldBsvhjEREc&pp=ygUJTGFuZ1NtaXRo', 'https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUJTGFuZ1NtaXRo']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some videos related to LangSmith:\n","https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUJTGFuZ1NtaXRo\n","https://www.youtube.com/watch?v=KcGoJPK-0tY&pp=ygUJTGFuZ1NtaXRo\n","https://www.youtube.com/watch?v=Hab2CV_0hpQ&pp=ygUJTGFuZ1NtaXRo\n","https://www.youtube.com/watch?v=ldBsvhjEREc&pp=ygUJTGFuZ1NtaXRo\n","https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUJTGFuZ1NtaXRo\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Give some video related to LangSmith',\n"," 'output': 'Here are some videos related to LangSmith:\\nhttps://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUJTGFuZ1NtaXRo\\nhttps://www.youtube.com/watch?v=KcGoJPK-0tY&pp=ygUJTGFuZ1NtaXRo\\nhttps://www.youtube.com/watch?v=Hab2CV_0hpQ&pp=ygUJTGFuZ1NtaXRo\\nhttps://www.youtube.com/watch?v=ldBsvhjEREc&pp=ygUJTGFuZ1NtaXRo\\nhttps://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUJTGFuZ1NtaXRo\\n'}"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["### **Use Memory or Chat History:**"],"metadata":{"id":"-bYFTg5Tv3pQ"}},{"cell_type":"markdown","source":["#### **Custom:**"],"metadata":{"id":"Nc_G0vXywJ_5"}},{"cell_type":"code","source":["# Here we pass in an empty list of messages for chat_history (because it is the first message in the chat):\n","\n","agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_27-lI9v3Kk","executionInfo":{"status":"ok","timestamp":1734525141550,"user_tz":-330,"elapsed":53205,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"77691d56-28c7-433f-8e13-b2ca65180669"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mHi Bob, it's nice to meet you! How can I help you today?\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'hi! my name is bob',\n"," 'chat_history': [],\n"," 'output': \"Hi Bob, it's nice to meet you! How can I help you today?\\n\"}"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, HumanMessage\n","\n","# Customly, provide the chat_history\n","agent_executor.invoke(\n","    {\n","        \"chat_history\": [\n","            HumanMessage(content=\"hi! my name is bob\"),\n","            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n","            HumanMessage(content=\"I am working at Accenture, as a Sr. Data Scientist\"),\n","            AIMessage(content=\"That's awesome, Bob! It sounds like you have a lot of expertise in data science.\"),\n","        ],\n","        \"input\": \"what's my name and where I am working?\",\n","    }\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1e59Qpsv3M-","executionInfo":{"status":"ok","timestamp":1734525315055,"user_tz":-330,"elapsed":1120,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"c2a6ff58-d6b8-451f-c6b1-4f350d31f14d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYour name is Bob, and you work at Accenture as a Senior Data Scientist.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'chat_history': [HumanMessage(content='hi! my name is bob', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n","  HumanMessage(content='I am working at Accenture, as a Sr. Data Scientist', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"That's awesome, Bob! It sounds like you have a lot of expertise in data science.\", additional_kwargs={}, response_metadata={})],\n"," 'input': \"what's my name and where I am working?\",\n"," 'output': 'Your name is Bob, and you work at Accenture as a Senior Data Scientist.\\n'}"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["#### **Real-Time Memory:**"],"metadata":{"id":"O0e2VAjyxLDl"}},{"cell_type":"code","source":["from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory"],"metadata":{"id":"vFi0rGt4v3Pd","executionInfo":{"status":"ok","timestamp":1734525494041,"user_tz":-330,"elapsed":417,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# store the session information in message_history:\n","\n","message_history = ChatMessageHistory()\n","message_history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtf4LtIGxWi5","executionInfo":{"status":"ok","timestamp":1734525589760,"user_tz":-330,"elapsed":425,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"e3deda71-8420-4d46-e19d-ea3aa7985b69"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InMemoryChatMessageHistory(messages=[])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["# Agent Executor with Memory:\n","\n","agent_with_chat_history = RunnableWithMessageHistory(\n","    agent_executor,\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    lambda session_id: message_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")"],"metadata":{"id":"_IUnzfLgx8Je","executionInfo":{"status":"ok","timestamp":1734525718083,"user_tz":-330,"elapsed":435,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["**Start Invoking using Memory and Agent Executor:**"],"metadata":{"id":"XXN3CUTHyaik"}},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4twTJJEmxWnj","executionInfo":{"status":"ok","timestamp":1734525729579,"user_tz":-330,"elapsed":7240,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"6336cc0b-af32-497a-94b7-c268d94f85ce"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI understand that you're an AI/ML engineer and are currently looking for a job.  It's a competitive field, but don't get discouraged!  I can offer some help with your job search.  To give you the best advice, could you tell me more about your situation? For example:\n","\n","* **What kind of AI/ML roles are you targeting?** (e.g., Research, Data Science, Machine Learning Engineering, etc.)\n","* **What's your experience level?** (e.g., Entry-level, Mid-level, Senior)\n","* **What are your main skills and strengths?** (e.g., specific programming languages, ML algorithms, cloud platforms, etc.)\n","* **What have you tried so far in your job search?** (e.g., applying online, networking, attending career fairs)\n","\n","The more information you can provide, the better I can assist you.  I can help with things like:\n","\n","* **Optimizing your resume and LinkedIn profile.**\n","* **Practicing for interviews.**\n","* **Identifying relevant job opportunities.**\n","* **Finding resources for skill development.**\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': \"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\",\n"," 'chat_history': [],\n"," 'output': \"I understand that you're an AI/ML engineer and are currently looking for a job.  It's a competitive field, but don't get discouraged!  I can offer some help with your job search.  To give you the best advice, could you tell me more about your situation? For example:\\n\\n* **What kind of AI/ML roles are you targeting?** (e.g., Research, Data Science, Machine Learning Engineering, etc.)\\n* **What's your experience level?** (e.g., Entry-level, Mid-level, Senior)\\n* **What are your main skills and strengths?** (e.g., specific programming languages, ML algorithms, cloud platforms, etc.)\\n* **What have you tried so far in your job search?** (e.g., applying online, networking, attending career fairs)\\n\\nThe more information you can provide, the better I can assist you.  I can help with things like:\\n\\n* **Optimizing your resume and LinkedIn profile.**\\n* **Practicing for interviews.**\\n* **Identifying relevant job opportunities.**\\n* **Finding resources for skill development.**\\n\"}"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"Give me 2 video urls related to AI and ML.\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9CNYaslsxWqF","executionInfo":{"status":"ok","timestamp":1734525880426,"user_tz":-330,"elapsed":105177,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"fdd9b001-c424-45ab-bfbf-01ffd688bd17"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `youtube_search` with `{'query': 'AI and ML, 2'}`\n","\n","\n","\u001b[0m\u001b[38;5;200m\u001b[1;3m['https://www.youtube.com/watch?v=4RixMPF4xis&pp=ygUJQUkgYW5kIE1M', 'https://www.youtube.com/watch?v=qYNweeDHiyU&pp=ygUJQUkgYW5kIE1M']\u001b[0m\u001b[32;1m\u001b[1;3mHere are two YouTube video URLs related to AI and ML:\n","\n","* https://www.youtube.com/watch?v=4RixMPF4xis&pp=ygUJQUkgYW5kIE1M\n","* https://www.youtube.com/watch?v=qYNweeDHiyU&pp=ygUJQUkgYW5kIE1M\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'Give me 2 video urls related to AI and ML.',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"I understand that you're an AI/ML engineer and are currently looking for a job.  It's a competitive field, but don't get discouraged!  I can offer some help with your job search.  To give you the best advice, could you tell me more about your situation? For example:\\n\\n* **What kind of AI/ML roles are you targeting?** (e.g., Research, Data Science, Machine Learning Engineering, etc.)\\n* **What's your experience level?** (e.g., Entry-level, Mid-level, Senior)\\n* **What are your main skills and strengths?** (e.g., specific programming languages, ML algorithms, cloud platforms, etc.)\\n* **What have you tried so far in your job search?** (e.g., applying online, networking, attending career fairs)\\n\\nThe more information you can provide, the better I can assist you.  I can help with things like:\\n\\n* **Optimizing your resume and LinkedIn profile.**\\n* **Practicing for interviews.**\\n* **Identifying relevant job opportunities.**\\n* **Finding resources for skill development.**\\n\", additional_kwargs={}, response_metadata={})],\n"," 'output': 'Here are two YouTube video URLs related to AI and ML:\\n\\n* https://www.youtube.com/watch?v=4RixMPF4xis&pp=ygUJQUkgYW5kIE1M\\n* https://www.youtube.com/watch?v=qYNweeDHiyU&pp=ygUJQUkgYW5kIE1M\\n'}"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["agent_with_chat_history.invoke(\n","    {\"input\": \"What is my name and where I am working?\"},\n","    # This is needed because in most real world scenarios, a session id is needed\n","    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n","    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWsNWWz7xWsQ","executionInfo":{"status":"ok","timestamp":1734525960047,"user_tz":-330,"elapsed":2065,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"ac9ea4d2-83a2-48b1-9799-b6a180ef52d1"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYou told me your name is Dibyendu and that you are an AI/ML Engineer. You mentioned you are currently looking for a job, so you are not currently employed.\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is my name and where I am working?',\n"," 'chat_history': [HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"I understand that you're an AI/ML engineer and are currently looking for a job.  It's a competitive field, but don't get discouraged!  I can offer some help with your job search.  To give you the best advice, could you tell me more about your situation? For example:\\n\\n* **What kind of AI/ML roles are you targeting?** (e.g., Research, Data Science, Machine Learning Engineering, etc.)\\n* **What's your experience level?** (e.g., Entry-level, Mid-level, Senior)\\n* **What are your main skills and strengths?** (e.g., specific programming languages, ML algorithms, cloud platforms, etc.)\\n* **What have you tried so far in your job search?** (e.g., applying online, networking, attending career fairs)\\n\\nThe more information you can provide, the better I can assist you.  I can help with things like:\\n\\n* **Optimizing your resume and LinkedIn profile.**\\n* **Practicing for interviews.**\\n* **Identifying relevant job opportunities.**\\n* **Finding resources for skill development.**\\n\", additional_kwargs={}, response_metadata={}),\n","  HumanMessage(content='Give me 2 video urls related to AI and ML.', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content='Here are two YouTube video URLs related to AI and ML:\\n\\n* https://www.youtube.com/watch?v=4RixMPF4xis&pp=ygUJQUkgYW5kIE1M\\n* https://www.youtube.com/watch?v=qYNweeDHiyU&pp=ygUJQUkgYW5kIE1M\\n', additional_kwargs={}, response_metadata={})],\n"," 'output': 'You told me your name is Dibyendu and that you are an AI/ML Engineer. You mentioned you are currently looking for a job, so you are not currently employed.\\n'}"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["message_history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wo3ACkq2teiN","executionInfo":{"status":"ok","timestamp":1734525975592,"user_tz":-330,"elapsed":469,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"c1919192-6c6e-44d3-b4f6-cdbca3847966"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InMemoryChatMessageHistory(messages=[HumanMessage(content=\"hi! I'm Dibyendu, Working as a AI/ML Engineer, but still not getting job\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"I understand that you're an AI/ML engineer and are currently looking for a job.  It's a competitive field, but don't get discouraged!  I can offer some help with your job search.  To give you the best advice, could you tell me more about your situation? For example:\\n\\n* **What kind of AI/ML roles are you targeting?** (e.g., Research, Data Science, Machine Learning Engineering, etc.)\\n* **What's your experience level?** (e.g., Entry-level, Mid-level, Senior)\\n* **What are your main skills and strengths?** (e.g., specific programming languages, ML algorithms, cloud platforms, etc.)\\n* **What have you tried so far in your job search?** (e.g., applying online, networking, attending career fairs)\\n\\nThe more information you can provide, the better I can assist you.  I can help with things like:\\n\\n* **Optimizing your resume and LinkedIn profile.**\\n* **Practicing for interviews.**\\n* **Identifying relevant job opportunities.**\\n* **Finding resources for skill development.**\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Give me 2 video urls related to AI and ML.', additional_kwargs={}, response_metadata={}), AIMessage(content='Here are two YouTube video URLs related to AI and ML:\\n\\n* https://www.youtube.com/watch?v=4RixMPF4xis&pp=ygUJQUkgYW5kIE1M\\n* https://www.youtube.com/watch?v=qYNweeDHiyU&pp=ygUJQUkgYW5kIE1M\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name and where I am working?', additional_kwargs={}, response_metadata={}), AIMessage(content='You told me your name is Dibyendu and that you are an AI/ML Engineer. You mentioned you are currently looking for a job, so you are not currently employed.\\n', additional_kwargs={}, response_metadata={})])"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":[],"metadata":{"id":"Qmg0sQ8Wza2w"},"execution_count":null,"outputs":[]}]}