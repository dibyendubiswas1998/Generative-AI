{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOx1NOHb8cER8RvU+k7g8OH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **RAG Fusion + Rank Reciprocal Fusion:**"],"metadata":{"id":"gqOVcHmitb6H"}},{"cell_type":"code","source":["# install necessary libaries:\n","\n","!pip install sentence_transformers -qU\n","!pip install langchain langchain_community chromadb pypdf langchain_google_genai -qU"],"metadata":{"id":"-Iq0nlUFtERA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load The PDF documents:**"],"metadata":{"id":"h9X8OQYGwaRv"}},{"cell_type":"code","source":["!pip install unstructured pypdfium2 -qU"],"metadata":{"id":"vZTIEceztEVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFium2Loader\n","\n","file_path_1 = \"/content/Generative AI Documentation.pdf\"\n","loader = PyPDFium2Loader(file_path_1)\n","documents = loader.load()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cbReDgttEZh","executionInfo":{"status":"ok","timestamp":1720096820388,"user_tz":-330,"elapsed":1193,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"dd908842-aabb-4748-ff13-3c7ab44b27a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n","  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"]}]},{"cell_type":"code","source":["len(documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AJCNo8ltEfR","executionInfo":{"status":"ok","timestamp":1720096826401,"user_tz":-330,"elapsed":6,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"6d7f7423-1b23-4543-e0e2-8e587c916ba2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["36"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from IPython.display import display, Markdown\n","\n","display(Markdown(documents[0].page_content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"M25fZXC7tEkA","executionInfo":{"status":"ok","timestamp":1720096883103,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"76fd1ec2-251a-4c4c-e3cc-3db60102a173"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Generative AI dibyendubiswas1998.gmail.com\r\nPage | 1\r\nGenerative AI\r\nIntroduction:\r\nGenerative AI is a type of artificial intelligence technology that can produce various types of content, including text, \r\nimagery, audio and synthetic data. The recent buzz around generative AI has been driven by the simplicity of new \r\nuser interfaces for creating high-quality text, graphics and videos in a matter of seconds.\r\nThe technology, it should be noted, is not brand-new. Generative AI was introduced in the 1960s in chatbots. But it \r\nwas not until 2014, with the introduction of generative adversarial networks, or GANs -- a type of machine learning \r\nalgorithm -- that generative AI could create convincingly authentic images, videos and audio of real people.\r\nGenerative AI refers to a class of artificial intelligence (AI) systems that are designed to generate new content or \r\ndata rather than simply analyzing or recognizing existing patterns. These systems have the ability to create new and \r\noriginal outputs, such as images, text, music, and more, based on patterns and knowledge learned from a dataset \r\nduring the training phase.\r\nOne popular type of generative AI is Generative Adversarial Networks (GANs). GANs consist of two neural networks \r\n– a generator and a discriminator – that are trained together in a competitive manner. The generator generates \r\nsynthetic data, and the discriminator evaluates whether the generated data is real or fake. Through this adversarial \r\ntraining process, the generator improves over time, creating outputs that become increasingly difficult for the \r\ndiscriminator to distinguish from real data.\r\nGenerative AI has been applied in various fields, including image synthesis, text generation, style transfer, and even \r\nin creating realistic deep fake videos. While generative AI has shown remarkable capabilities, it also raises ethical \r\nconcerns, particularly regarding the potential misuse of the technology for creating deceptive or malicious content. \r\nResearchers and developers are actively working on both advancing the capabilities of generative AI and addressing \r\nits ethical implications.\r\nWhere Generative AI exists.:\r\n● Machine Learning is the subset of Artificial Intelligence\r\n● Deep Learning is the subset of Machine Learning\r\n● Generative AI is the subset of Deep Learning \n"},"metadata":{}}]},{"cell_type":"markdown","source":["## **Chunking:**"],"metadata":{"id":"TpvQuYy4xGNM"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=250)"],"metadata":{"id":"N69Dzwl_tEoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunks = text_splitter.split_documents(documents)"],"metadata":{"id":"GMV-XXcdtEs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(chunks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vocdaOE5tEwt","executionInfo":{"status":"ok","timestamp":1720097017172,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"b5f035a2-cfa8-4fed-b5d1-3a52d7c94c42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["132"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["display(Markdown(chunks[0].page_content))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150},"id":"hyHGFdT0xTg4","executionInfo":{"status":"ok","timestamp":1720097028739,"user_tz":-330,"elapsed":496,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"9ab120eb-2845-482d-e9fb-f12771c7fd41"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Generative AI dibyendubiswas1998.gmail.com\r\nPage | 1\r\nGenerative AI\r\nIntroduction:\r\nGenerative AI is a type of artificial intelligence technology that can produce various types of content, including text, \r\nimagery, audio and synthetic data. The recent buzz around generative AI has been driven by the simplicity of new \r\nuser interfaces for creating high-quality text, graphics and videos in a matter of seconds.\r\nThe technology, it should be noted, is not brand-new. Generative AI was introduced in the 1960s in chatbots. But it \r\nwas not until 2014, with the introduction of generative adversarial networks, or GANs -- a type of machine learning \r\nalgorithm -- that generative AI could create convincingly authentic images, videos and audio of real people.\r\nGenerative AI refers to a class of artificial intelligence (AI) systems that are designed to generate new content or \r\ndata rather than simply analyzing or recognizing existing patterns. These systems have the ability to create new and"},"metadata":{}}]},{"cell_type":"markdown","source":["## **Load Embedding Model:**"],"metadata":{"id":"0th6xmGtxhgI"}},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","embeddings = HuggingFaceEmbeddings(model_name=model_name)"],"metadata":{"id":"Fbvd1bNPxg4t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Load LLM:**"],"metadata":{"id":"hGPJSIr0y2np"}},{"cell_type":"code","source":["from google.colab import userdata\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","\n","GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-pro\",\n","    google_api_key=GEMINI_API_KEY,\n","    temperature=0.5,\n","    max_tokens=1024,\n","    max_length=1024,\n",")"],"metadata":{"id":"JQ62hl7Wy2Ks"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Insert Embeddings into Vector Database:**"],"metadata":{"id":"w6-LMOQYxq3b"}},{"cell_type":"code","source":["from langchain.vectorstores import Chroma\n","import chromadb"],"metadata":{"id":"-BaOC0ncxg7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DB_DIR = \"ChromaDB\"\n","\n","client_settings = chromadb.config.Settings(\n","    is_persistent=True,\n","    persist_directory=DB_DIR,\n","    anonymized_telemetry=False,\n",")"],"metadata":{"id":"ugNYj4HtxhB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorstore = Chroma.from_documents(chunks,\n","                                    embeddings,\n","                                    client_settings=client_settings,\n","                                    collection_name=\"genai\",\n","                                    collection_metadata={\"hnsw\":\"cosine\"}\n","              )"],"metadata":{"id":"4WhwuosMxUo2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorstore.similarity_search(query='What is LLM?', k=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHh-PZeSx6r3","executionInfo":{"status":"ok","timestamp":1720097234014,"user_tz":-330,"elapsed":515,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"76ae6118-cadd-45a0-c91c-7de9dfb0eb70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'page': 9, 'source': '/content/Generative AI Documentation.pdf'}, page_content='What makes LLM so Powerful:\\r\\nIn case of LLM, one model can be used for a whole variety of tasks like: - Text generation, Chatbot, \\r\\nsummarizer, translation, code generation & so on.\\r\\nLLMs Model Architecture:\\r\\nLarge Language models are based on Transformer a type of Neural Network Architecture invented by \\r\\nGoogle.\\r\\nFew milestones in Large Language Model:\\r\\n\\uf0b7 BERT: Bidirectional Encoder Representations from Transformers (BERT) was developed by Google.\\r\\n\\uf0b7 GPT: GPT stands for \"Generative Pre-trained “Transformer”. The model was developed by OpenAI.\\r\\n\\uf0b7 XLM: Cross-lingual Language Model Pretraining by Guillaume Lample, Alexis Conneau.\\r\\n\\uf0b7 T5: The Text-to-Text Transformer, it was created by Google AI.\\r\\n\\uf0b7 Megatron: Megatron is a large, powerful transformer developed by the Applied Deep Learning \\r\\nResearch team at NVIDIA.\\r\\n\\uf0b7 M2M-100: Multilingual encoder-decoder (seq-to-seq) model researcher at Facebook.\\r\\nTransformer Tree:'),\n"," Document(metadata={'page': 10, 'source': '/content/Generative AI Documentation.pdf'}, page_content='Generative AI dibyendubiswas1998.gmail.com\\r\\nPage | 11\\r\\n \\r\\nOpenAI based LLM models:\\r\\nWhat can LLMs be used for:\\r\\n\\uf0b7 Text Classification,\\r\\n\\uf0b7 Text Generation,\\r\\n\\uf0b7 Text Summarization,\\r\\n\\uf0b7 Conversation AI like chatbot, Question Answering,\\r\\n\\uf0b7 Speech recognition and Speech identification,\\r\\n\\uf0b7 Spelling Corrector, etc.\\r\\nNotes:\\r\\n\\uf0b7 Encoder based models are generally used for classification kind of tasks.\\r\\n\\uf0b7 Decoder based models are generally used for generation kind of tasks.\\r\\n\\uf0b7 Encoder-Decoder based models are generally used for translation kind of tasks.\\r\\n\\uf0b7 LLM is way to implement the Generative AI.'),\n"," Document(metadata={'page': 9, 'source': '/content/Generative AI Documentation.pdf'}, page_content='knowledge for the flower recognition task.\\r\\nResearch Paper: \\r\\n\\uf0b7 Universal Language Model File-Tuning for Text Classification.\\r\\n\\uf0b7 BERT Research Paper.\\r\\n\\uf0b7 GPT Research Paper.\\r\\nWhat is LLM: \\r\\nA large Language model is a trained deep learning model that understands and generate text in a human like fashion.\\r\\nLLMs are good at Understanding and generating human language.\\r\\nWhy it calls it Large Language Model:\\r\\nBecause of the size and complexity of the Neural Network as well as the size of the dataset that it was \\r\\ntrained on. Researchers started to make these models large and trained on huge datasets.\\r\\nThat they started showing impressive results like understanding complex Natural Language and \\r\\ngenerating language more eloquently than ever.\\r\\nWhat makes LLM so Powerful:\\r\\nIn case of LLM, one model can be used for a whole variety of tasks like: - Text generation, Chatbot, \\r\\nsummarizer, translation, code generation & so on.\\r\\nLLMs Model Architecture:'),\n"," Document(metadata={'page': 3, 'source': '/content/Generative AI Documentation.pdf'}, page_content=\"\\uf0b7 Fine-tuning: After pre-training, LLMs can be fine-tuned on specific tasks or domains with smaller \\r\\ndatasets. This fine-tuning process helps adapt the model's general language understanding to \\r\\nmore specialized tasks.\\r\\n\\uf0b7 Versatility: LLMs are designed to be versatile and applicable to a wide range of NLP tasks. Their \\r\\nlarge capacity allows them to generalize well across different domains and perform competitively \\r\\non various benchmarks.\\r\\n\\uf0b7 Generative Capability: LLMs, as the name suggests, have the ability to generate coherent and \\r\\ncontextually relevant text. This makes them valuable for tasks like text completion, creative \\r\\nwriting, and even conversation.\\r\\nWhile LLMs have demonstrated remarkable capabilities, they also raise considerations regarding ethical \\r\\nuse, potential biases in the training data, and the environmental impact of training such large models. \\r\\nResearchers and developers are actively working on addressing these challenges to ensure responsible and\"),\n"," Document(metadata={'page': 28, 'source': '/content/Generative AI Documentation.pdf'}, page_content=\"Intellectual Property Considerations: Companies should be aware of the licensing terms associated with \\r\\nopen-source models to ensure compliance with intellectual property regulations.\\r\\nLimited Tailoring to Specific Needs: While customization is possible, it may not fully address the specific \\r\\nrequirements of certain niche or highly specialized tasks.\\r\\nWhy some of LLM models not able to load?\\r\\nIt’s a memory that used in your system. You can use at least good configuration machine.\\r\\nWhat are the factors should we consider during developing the applications using Generative AI or LLM models:\\r\\nDeveloping applications using Generative AI or Large Language Models (LLMs) involves careful consideration of \\r\\nvarious factors to ensure successful and responsible deployment. \\r\\nHere are key factors to consider during the development of applications using Generative AI or LLM models:\\r\\nData Quality & Diversity: Ensure high-quality and diverse training data to improve the model's\")]"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## **Create Retriever:**"],"metadata":{"id":"ro-UoAHfyUY0"}},{"cell_type":"code","source":["retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}, search_type=\"mmr\")\n","retriever.get_relevant_documents(\"What is LLM?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cuJBI-8yIEe","executionInfo":{"status":"ok","timestamp":1720097331400,"user_tz":-330,"elapsed":500,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"a9bee26f-d658-43d7-ae8b-30631af967ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'page': 9, 'source': '/content/Generative AI Documentation.pdf'}, page_content='What makes LLM so Powerful:\\r\\nIn case of LLM, one model can be used for a whole variety of tasks like: - Text generation, Chatbot, \\r\\nsummarizer, translation, code generation & so on.\\r\\nLLMs Model Architecture:\\r\\nLarge Language models are based on Transformer a type of Neural Network Architecture invented by \\r\\nGoogle.\\r\\nFew milestones in Large Language Model:\\r\\n\\uf0b7 BERT: Bidirectional Encoder Representations from Transformers (BERT) was developed by Google.\\r\\n\\uf0b7 GPT: GPT stands for \"Generative Pre-trained “Transformer”. The model was developed by OpenAI.\\r\\n\\uf0b7 XLM: Cross-lingual Language Model Pretraining by Guillaume Lample, Alexis Conneau.\\r\\n\\uf0b7 T5: The Text-to-Text Transformer, it was created by Google AI.\\r\\n\\uf0b7 Megatron: Megatron is a large, powerful transformer developed by the Applied Deep Learning \\r\\nResearch team at NVIDIA.\\r\\n\\uf0b7 M2M-100: Multilingual encoder-decoder (seq-to-seq) model researcher at Facebook.\\r\\nTransformer Tree:'),\n"," Document(metadata={'page': 5, 'source': '/content/Generative AI Documentation.pdf'}, page_content='Generative AI dibyendubiswas1998.gmail.com\\r\\nPage | 6\\r\\n\\uf0b7 Lack of Interpretability: The internal workings of LLMs are often complex and lack interpretability. \\r\\nUnderstanding why a model makes a specific prediction or generates particular output can be challenging, \\r\\nlimiting trust and transparency in certain applications.\\r\\n\\uf0b7 Ethical Concerns: Generative AI models, including LLMs, can be used to create deepfake content or \\r\\ngenerate misleading information. This raises ethical concerns related to misinformation, fake news, and \\r\\npotential malicious uses of the technology.\\r\\n\\uf0b7 Overfitting to training data: LLMs can be sensitive to the data on which they are trained. If the training data \\r\\nis not representative or contains anomalies, the model may produce unreliable or unexpected results when \\r\\nfaced with inputs outside its training distribution.\\r\\n\\uf0b7 Inability to Reason: LLMs lack true understanding and reasoning abilities. They generate responses based'),\n"," Document(metadata={'page': 5, 'source': '/content/Generative AI Documentation.pdf'}, page_content='faced with inputs outside its training distribution.\\r\\n\\uf0b7 Inability to Reason: LLMs lack true understanding and reasoning abilities. They generate responses based \\r\\non patterns learned from data but may struggle with tasks requiring deep comprehension, logical reasoning, \\r\\nor common-sense understanding.\\r\\n\\uf0b7 High Inference Cost: While fine-tuned LLMs can achieve impressive performance, the cost of inference \\r\\n(using the model to make predictions) in terms of computation and latency can be high, limiting real-time \\r\\napplications in resource-constrained environments.\\r\\n\\uf0b7 Limited Context Understanding: LLMs may sometimes struggle with understanding context over longer \\r\\npassages of text. They might have difficulty maintaining coherence and understanding relationships \\r\\nbetween distant parts of a document.\\r\\nAddressing these disadvantages involves ongoing research and development efforts. Researchers are actively'),\n"," Document(metadata={'page': 34, 'source': '/content/Generative AI Documentation.pdf'}, page_content='User can ask question, then question pass to vector database, \\r\\nafter that it return top most similarity documents or results.\\r\\nNow top most results or \\r\\ndocuments are pass to the LLM \\r\\nmodel.\\r\\nSend the question to LLM\\r\\nGet the response from LLM\\r\\nLLM\\r\\nVector \\r\\nDB End User\\r\\nData \\r\\nChunking\\r\\nBreak down the \\r\\ncollected data into \\r\\nmanageable chunks'),\n"," Document(metadata={'page': 4, 'source': '/content/Generative AI Documentation.pdf'}, page_content='with several disadvantages and challenges:\\r\\n\\uf0b7 Computational Resources: Training and fine-tuning LLMs require massive computational resources, \\r\\nincluding powerful GPUs or TPUs. This can make these models inaccessible for smaller research groups or \\r\\norganizations with limited resources.\\r\\n\\uf0b7 Energy Consumption: The training of large models consumes significant amounts of energy, contributing \\r\\nto environmental concerns. The carbon footprint associated with training large models has raised ethical \\r\\nquestions about the environmental impact of such computational demands.\\r\\n\\uf0b7 Data Bias and Fairness: LLMs learn from vast amounts of data collected from the internet, which may \\r\\ncontain biases. The models can inadvertently perpetuate and even amplify existing biases present in the \\r\\ntraining data, leading to biased outputs and discriminatory behavior.')]"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## **Without RAG Fusion (Normal Way):**"],"metadata":{"id":"7O_M2jozys1I"}},{"cell_type":"code","source":["from operator import itemgetter\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.schema.output_parser import StrOutputParser\n","from langchain.schema.runnable import RunnableLambda, RunnablePassthrough"],"metadata":{"id":"4ePSRPvYyTWc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Create Simple Prompt:**"],"metadata":{"id":"tAyj1nqpzRMB"}},{"cell_type":"code","source":["template = \"\"\"Answer the question based only on the following context:\n","{context}\n","\n","Question: {question}\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template)"],"metadata":{"id":"9wH2Rrr3zIQc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Create Simple Chain:**"],"metadata":{"id":"LXGaA5e9zUgn"}},{"cell_type":"code","source":["chain = (\n","    {\"context\": retriever, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")"],"metadata":{"id":"XitvWyQyyTZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Generate Response:**"],"metadata":{"id":"U4cenH3kzZ2l"}},{"cell_type":"code","source":["chain.invoke(\"What is LLM?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"HJynWltxyTb4","executionInfo":{"status":"ok","timestamp":1720097581719,"user_tz":-330,"elapsed":1760,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"b90721c1-534f-4f45-cb9c-87e1d82b523e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Large Language models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["chain.invoke(\"Tell me something about LLM.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"HYQXqi2oyTe9","executionInfo":{"status":"ok","timestamp":1720097622305,"user_tz":-330,"elapsed":1943,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"c176ad18-1842-4cdb-885b-f3d37088acd9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'LLM (Large Language Model) is a type of neural network architecture based on Transformer. It is capable of performing various tasks such as text generation, chatbot, summarization, translation, and code generation.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["## **With RAG Fusion + Reciprocal RAG Fusion:**"],"metadata":{"id":"i4DY2na51Ibb"}},{"cell_type":"code","source":["from langchain.schema.output_parser import StrOutputParser\n","from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n","from langchain.prompts import ChatMessagePromptTemplate, PromptTemplate"],"metadata":{"id":"MSfJDtkMyThl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Write a prompt to generate synthetic questions based on original question:**"],"metadata":{"id":"-z00qKap14uE"}},{"cell_type":"code","source":["prompt = ChatPromptTemplate(input_variables=['original_query'],\n","                            messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[],\n","                            template='You are a helpful assistant that generates multiple search queries based on a single input query.')),\n","                            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['original_query'], template='Generate multiple search queries related to: {question} \\n OUTPUT (4 queries):'))])"],"metadata":{"id":"Ejh9Pa76yTk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_queries = (\n","    prompt | llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",")\n","generate_queries"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8l73S-WyTnm","executionInfo":{"status":"ok","timestamp":1720098128300,"user_tz":-330,"elapsed":554,"user":{"displayName":"Dibyendu Biswas.","userId":"13544031185281536447"}},"outputId":"6ee987cd-3f0f-4a0a-811a-10e49b1a4dbd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant that generates multiple search queries based on a single input query.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='Generate multiple search queries related to: {question} \\n OUTPUT (4 queries):'))])\n","| ChatGoogleGenerativeAI(model='models/gemini-pro', google_api_key=SecretStr('**********'), temperature=0.5, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7830ab765030>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x7830ab7981f0>, default_metadata=())\n","| StrOutputParser()\n","| RunnableLambda(lambda x: x.split('\\n'))"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["### **Create Reciprocal Rank Fusion Function:**"],"metadata":{"id":"12T2TEEK1t6w"}},{"cell_type":"code","source":["from langchain.load import dumps, loads\n","\n","\n","def reciprocal_rank_fusion(results: list[list], k=60):\n","    fused_scores = {}\n","    for docs in results:\n","        # Assumes the docs are returned in sorted order of relevance\n","        for rank, doc in enumerate(docs):\n","            doc_str = dumps(doc)\n","            if doc_str not in fused_scores:\n","                fused_scores[doc_str] = 0\n","            previous_score = fused_scores[doc_str]\n","            fused_scores[doc_str] += 1 / (rank + k)\n","\n","    reranked_results = [\n","        (loads(doc), score)\n","        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n","    ]\n","    return reranked_results"],"metadata":{"id":"WVP5sJXkyTrZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Create refusion chain for generating synthetic questions:**"],"metadata":{"id":"kePIPlei2Hgs"}},{"cell_type":"code","source":["ragfusion_chain = generate_queries | retriever.map() | reciprocal_rank_fusion"],"metadata":{"id":"ids4J3XzyTuy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ragfusion_chain.invoke({\"question\": \"What is LLM?\"})"],"metadata":{"id":"t3o3zOy4yTyB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Now Create Reciprocal Rag Fusion chain:**"],"metadata":{"id":"1JhEQTG020k-"}},{"cell_type":"code","source":["from langchain.schema.runnable import RunnablePassthrough\n","\n","template = \"\"\"Answer the question based only on the following context:\n","{context}\n","\n","Question: {question}\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template)\n","\n","full_rag_fusion_chain = (\n","    {\n","        \"context\": ragfusion_chain,\n","        \"question\": RunnablePassthrough()\n","    }\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")"],"metadata":{"id":"YfZADt242TRA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_rag_fusion_chain.input_schema.schema()"],"metadata":{"id":"bmuQbuaw20Ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_rag_fusion_chain.invoke({\"question\": \"Tell me about Generative AI?\"})"],"metadata":{"id":"YGYG62KX20Ed"},"execution_count":null,"outputs":[]}]}